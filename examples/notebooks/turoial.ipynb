{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Batchable Inverse Kinematics with MJINX\n",
        "\n",
        "Welcome to this tutorial where we'll explore how to solve inverse kinematics (IK) problems efficiently in batch using `mjinx`. \n",
        "\n",
        "We'll work with a 7-degree-of-freedom (7-DoF) robotic arm and demonstrate how to:\n",
        "- Track batch of target poses (positions and orientations) simultaneously\n",
        "- Enforce joint limits to keep the robot's motion within safe bounds\n",
        "- Implement additional safety constraints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before moving forward we need to set up the environment and GPU, make sure to choose one in runtime settings in Google Colab.\n",
        "\n",
        "If you are running this on a local machine, you can skip the GPU setup."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lhd4p6mihYeB"
      },
      "outputs": [],
      "source": [
        "# Set up GPU rendering. \n",
        "# # from google.colab import files\n",
        "# import distutils.util\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "\n",
        "# Configure MuJoCo to use the EGL rendering backend (requires GPU)\n",
        "print('Setting environment variable to use GPU rendering:')\n",
        "%env MUJOCO_GL=egl\n",
        "\n",
        "# Graphics and plotting.\n",
        "print('Installing mediapy:')\n",
        "!command -v ffmpeg >/dev/null || (apt update && apt install -y ffmpeg)\n",
        "\n",
        "\n",
        "# SETUP XLA FLAGS\n",
        "import os\n",
        "os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'\n",
        "\n",
        "if subprocess.run('nvidia-smi').returncode:\n",
        "  raise RuntimeError(\n",
        "      'Cannot communicate with GPU. '\n",
        "      'Make sure you are using a GPU Colab runtime. '\n",
        "      'Go to the Runtime menu and select Choose runtime type.')\n",
        "\n",
        "# Add an ICD config so that glvnd can pick up the Nvidia EGL driver.\n",
        "# This is usually installed as part of an Nvidia driver package, but the Colab\n",
        "# kernel doesn't install its driver via APT, and as a result the ICD is missing.\n",
        "# (https://github.com/NVIDIA/libglvnd/blob/master/src/EGL/icd_enumeration.md)\n",
        "NVIDIA_ICD_CONFIG_PATH = '/usr/share/glvnd/egl_vendor.d/10_nvidia.json'\n",
        "if not os.path.exists(NVIDIA_ICD_CONFIG_PATH):\n",
        "  with open(NVIDIA_ICD_CONFIG_PATH, 'w') as f:\n",
        "    f.write(\"\"\"{\n",
        "    \"file_format_version\" : \"1.0.0\",\n",
        "    \"ICD\" : {\n",
        "        \"library_path\" : \"libEGL_nvidia.so.0\"\n",
        "    }\n",
        "}\n",
        "\"\"\")\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To see if ef NVIDIA GPU is properly available let us envoke the `nvidia-smi`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once GPU is set up, let us install mjinx with `examples` tag, more on installation in the [installation guide](https://github.com/based-robotics/mjinx?tab=readme-ov-file#installation). \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install mjinx[examples]\n",
        "clear_output()\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import mujoco as mj\n",
        "import mujoco.mjx as mjx\n",
        "import numpy as np\n",
        "import mediapy as media\n",
        "from time import perf_counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " As robot we will use IIWA 14 from `robot_descriptions` package. Let us upload the model and initialize the MuJoCo model and data as well as MJX model.\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "W2b0rsA4pMm9"
      },
      "outputs": [],
      "source": [
        "from robot_descriptions.iiwa14_mj_description import MJCF_PATH\n",
        "mj_model = mj.MjModel.from_xml_path(MJCF_PATH)\n",
        "mj_data = mj.MjData(mj_model)\n",
        "\n",
        "mjx_model = mjx.put_model(mj_model)\n",
        "\n",
        "q_min = mj_model.jnt_range[:, 0].copy()\n",
        "q_max = mj_model.jnt_range[:, 1].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating problem formulation is as simple as:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOl8lbe-G9nu",
        "outputId": "d227987c-25d8-437e-b4c5-cf7701e6b6c0"
      },
      "outputs": [],
      "source": [
        "from mjinx.problem import Problem\n",
        "# Creating problem formulation\n",
        "problem = Problem(mjx_model, v_min=-5, v_max=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The problem formulation in MJINX is highly modular, and allows to add different components to the problem, all of them are defined in `mjinx.components` module.\n",
        "\n",
        "To make robot follow a pose trajectory we will use `FrameTask` component."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from mjinx.components.tasks import FrameTask\n",
        "# Creating task component\n",
        "frame_task = FrameTask(\"ee_task\", \n",
        "                       cost=1, # cost of the task in to the objective function\n",
        "                       gain=20, # gain of the task: dy = gain * (y_d - y)\n",
        "                       obj_name=\"link7\") # name of the object to track\n",
        "# Adding task to the problem\n",
        "problem.add_component(frame_task)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In `mjinx` we can add different types of constraints/barriers to the problem, them are defined in `mjinx.components.barriers` module.\n",
        "\n",
        "\n",
        "For instance, we may add `JointLimitBarrier` to ensure the robot doesn't hit the joint limits and `PositionBarrier`  to ensure the robot doesn't hit the environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importing all MJINX components\n",
        "from mjinx.components.barriers import JointBarrier, PositionBarrier\n",
        "\n",
        "joints_barrier = JointBarrier(\"jnt_range\", gain=10)\n",
        "problem.add_component(joints_barrier)\n",
        "\n",
        "position_barrier = PositionBarrier(\n",
        "    \"ee_barrier\",\n",
        "    gain=100,\n",
        "    obj_name=\"link7\",\n",
        "    limit_type=\"max\",\n",
        "    p_max=0.5,\n",
        "    safe_displacement_gain=1e-2,\n",
        "    mask=[1, 0, 0],\n",
        ")\n",
        "problem.add_component(position_barrier)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To update the components in to the problem we need to recompile it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compiling the problem upon any parameters update\n",
        "problem_data = problem.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let us initialize the solver, here we will use `LocalIKSolver` which is QP based solver that uses local optimization over velocities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from mjinx.solvers import LocalIKSolver\n",
        "\n",
        "# Initializing solver and its initial state\n",
        "solver = LocalIKSolver(mjx_model, maxiter=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The velocities produced by the local IK solver need to be integrated to get the solution for the configuration. To do so we will use `integrate` function from `mjinx.configuration` module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from mjinx.configuration import integrate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let us create the batch of `N_batch` initial configurations and target poses that we will use to solve the inverse kinematics problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grZoUo0dpl0M",
        "outputId": "6077f7ae-22a6-48d5-830e-3f8f3be61fe3"
      },
      "outputs": [],
      "source": [
        "N_batch = 2000\n",
        "np.random.seed(42)\n",
        "q0 = jnp.array(\n",
        "    [\n",
        "        -1.4238753,\n",
        "        -1.7268502,\n",
        "        -0.84355015,\n",
        "        2.0962472,\n",
        "        2.1339328,\n",
        "        2.0837479,\n",
        "        -2.5521986,\n",
        "    ]\n",
        ")\n",
        "q = jnp.array(\n",
        "    [\n",
        "        np.clip(\n",
        "            q0\n",
        "            + np.random.uniform(\n",
        "                -0.1,\n",
        "                0.1,\n",
        "                size=(mj_model.nq),\n",
        "            ),\n",
        "            q_min + 1e-1,\n",
        "            q_max - 1e-1,\n",
        "        )\n",
        "        for _ in range(N_batch)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# First of all, data should be created via vmapped init function\n",
        "solver_data = jax.vmap(solver.init, in_axes=0)(v_init=jnp.zeros((N_batch, mjx_model.nv)))\n",
        "\n",
        "# To create a batch w.r.t. desired component's attributes, mjinx defines convinient wrapper\n",
        "# That sets all elements to None and allows user to mutate dataclasses of interest.\n",
        "# After exiting the Context Manager, you'll get immutable jax dataclass object.\n",
        "with problem.set_vmap_dimension() as empty_problem_data:\n",
        "    empty_problem_data.components[\"ee_task\"].target_frame = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To accelerate the computations we will compile the solve and integrate functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vmapping solve and integrate functions.\n",
        "solve_jit = jax.jit(jax.vmap(solver.solve, in_axes=(0, 0, empty_problem_data)))\n",
        "integrate_jit = jax.jit(jax.vmap(integrate, in_axes=(None, 0, 0, None)), static_argnames=[\"dt\"])\n",
        "\n",
        "t_warmup = perf_counter()\n",
        "print(\"Performing warmup calls...\")\n",
        "# Warmup iterations for JIT compilation\n",
        "frame_task.target_frame = np.array([[0.4, 0.2, 0.7, 1, 0, 0, 0] for _ in range(N_batch)])\n",
        "problem_data = problem.compile()\n",
        "opt_solution, _ = solve_jit(q, solver_data, problem_data)\n",
        "q_warmup = integrate_jit(mjx_model, q, opt_solution.v_opt, 0)\n",
        "\n",
        "t_warmup_duration = perf_counter() - t_warmup\n",
        "print(f\"Warmup completed in {t_warmup_duration:.3f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To help visualize the robot's movements, we'll use the `BatchVisualizer` tool, which allows us to see how our solutions play out in real-time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fetjYSbSLxff",
        "outputId": "e71c701c-be88-48f7-969f-5d61eb6d575b"
      },
      "outputs": [],
      "source": [
        "from mjinx.visualize import BatchVisualizer\n",
        "\n",
        "vis = BatchVisualizer(MJCF_PATH, n_models=5, alpha=0.5, record=True, passive_viewer=False)\n",
        "vis.camera.distance = 2\n",
        "vis.camera.azimuth = 100\n",
        "vis.camera.elevation = -25\n",
        "vis.camera.lookat = np.array([0, 0, 0.2])\n",
        "\n",
        "# Initialize a sphere marker for end-effector task\n",
        "vis.add_markers(\n",
        "    name=[f\"ee_marker_{i}\" for i in range(vis.n_models)],\n",
        "    size=0.05,\n",
        "    marker_alpha=0.4,\n",
        "    color_begin=np.array([0, 1.0, 0.53]),\n",
        "    color_end=np.array([0.38, 0.94, 1.0]),\n",
        "    n_markers=vis.n_models,\n",
        ")\n",
        "vis.add_markers(\n",
        "    name=\"blocking_plane\",\n",
        "    marker_type=mj.mjtGeom.mjGEOM_PLANE,\n",
        "    size=np.array([0.5, 0.5, 0.02]),\n",
        "    marker_alpha=0.3,\n",
        "    color_begin=np.array([1, 0, 0]),\n",
        ")\n",
        "\n",
        "vis.marker_data[\"blocking_plane\"].pos = np.array([position_barrier.p_max[0], 0, 0.3])\n",
        "vis.marker_data[\"blocking_plane\"].rot = np.array(\n",
        "    [\n",
        "        [0, 0, -1],\n",
        "        [0, 1, 0],\n",
        "        [1, 0, 0],\n",
        "    ]\n",
        ")\n",
        "\n",
        "vis.update(q[:: N_batch // vis.n_models])\n",
        "media.show_image(vis.frames[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we are ready to solve the IK, we will simulate the different target poses for the robot's end-effector and log the time it takes to solve the problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "qTB8l5RuqHpc"
      },
      "outputs": [],
      "source": [
        "dt = 2e-2\n",
        "ts = np.arange(0, 10, dt)\n",
        "\n",
        "# Performance tracking\n",
        "solve_times = []\n",
        "integrate_times = []\n",
        "n_steps = 0\n",
        "\n",
        "for t in ts:\n",
        "    # Changing desired values\n",
        "    frame_task.target_frame = np.array(\n",
        "        [\n",
        "            [\n",
        "                0.4 + 0.3 * np.sin(t + 2 * np.pi * i / N_batch),\n",
        "                0.2,\n",
        "                0.4 + 0.3 * np.cos(t + 2 * np.pi * i / N_batch),\n",
        "                1,\n",
        "                0,\n",
        "                0,\n",
        "                0,\n",
        "            ]\n",
        "            for i in range(N_batch)\n",
        "        ]\n",
        "    )\n",
        "    problem_data = problem.compile()\n",
        "\n",
        "    # Solving the instance of the problem\n",
        "    t1 = perf_counter()\n",
        "    opt_solution, solver_data = solve_jit(q, solver_data, problem_data)\n",
        "    t2 = perf_counter()\n",
        "    solve_times.append(t2 - t1)\n",
        "\n",
        "    # Integrating\n",
        "    t1 = perf_counter()\n",
        "    q = integrate_jit(\n",
        "        mjx_model,\n",
        "        q,\n",
        "        opt_solution.v_opt,\n",
        "        dt,\n",
        "    )\n",
        "    t2 = perf_counter()\n",
        "    integrate_times.append(t2 - t1)\n",
        "\n",
        "    # --- MuJoCo visualization ---\n",
        "    for i, q_i in enumerate(frame_task.target_frame.wxyz_xyz[:: N_batch // vis.n_models, -3:]):\n",
        "        vis.marker_data[f\"ee_marker_{i}\"].pos = q_i\n",
        "    vis.update(q[:: N_batch // vis.n_models])\n",
        "    n_steps += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us visualize the solutions, note that we visualize just tiny fraction of all the solutions in `N_batch`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cL7aBs-wiXAJ",
        "outputId": "bea34fb3-f3a2-4fb4-e4fe-41ede8996b63"
      },
      "outputs": [],
      "source": [
        "media.show_video(vis.frames, fps=round(1 / dt))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us check short performance report, do not hesitate to try it on your own machine or different colab GPUs!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjyFXtvikDpy",
        "outputId": "80418e63-7ef1-466b-e6c1-a0d0a63081ee"
      },
      "outputs": [],
      "source": [
        "# Performance report\n",
        "solve_times = np.array(solve_times)\n",
        "print(f\"\\n=== Performance Report for {N_batch} targets ===\\n\"\n",
        "      f\"Steps: {n_steps}\\n\"\n",
        "      f\"Solve time: {np.mean(solve_times)*1000:.1f} Â± {np.std(solve_times)*1000:.1f} ms\\n\" \n",
        "      f\"Rate: {1/np.mean(solve_times):.1f} Hz\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is just a glimpse of what you can do with `mjinx`. For more examples, including global/local IK on different robots and more advanced components, please refer to the [examples](https://github.com/based-robotics/mjinx/tree/main/examples). Stay tuned!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "mjinx_dev",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
